#+TITLE: Introduction to Artificial Intelligence
#+AUTHOR: Alexander Neville
#+DATE: [2023-02-19 Sun]
#+OPTIONS:

/Artificial intelligence/ is the study or creation of machine algorithms which may make observations and inferences in order to perform actionable decision making, as a human or animal might. In wider society /Machine learning/ and AI are two often conflated terms. ML is generally considered to be a specific discipline of AI, concerned with improving an algorithm's performance using past experience. This is not an article about ML.

* Philosophy of AI

There is not a universal consensus on definition of AI (which is a relatively ambiguous term), an issue revolving around the meaning of /intelligence/. It could be argued that the explicit goal of artificial intelligence is to simulate human performance. If a more abstract form of intelligence - artificial or otherwise - is adopted, then AI is not required to simulate human performance at all. Philosophy and logic attempt to codify the laws of thought; rationality and correct reasoning according to these rules could be achieved by a human or artificially by a machine. In some cases intelligence is said to be an internal property, as in a thought process or the reasoning employed, while in others it is evidenced in outward behaviour. These two conditions form four common interpretations of AI:

- Thinking as a human.
- Acting as a human.
- Thinking rationally.
- Acting rationally.

The /Turing test/ is passed if a human evaluator is unable to tell apart a human and AI algorithm through interrogation. The effectiveness, or outward intelligence, of the algorithm is measured by its ability to generate human like responses (its behaviour), independent of the underlying thought process. Many academics additionally agree that the most pragmatic approach to AI is not simulating the human thought process directly. The commonly cited analogy is that /artificial flight/ was not achieved by imitating the flight of birds exactly (Russell & Norvig (2021)). Thus, artificial intelligence is widely agreed to be the study and creation of algorithms capable of /acting rationally/, or working to reach the best possible outcome. Sometimes this is called the /standard model/ for AI.

* Agents

An /agent/ is an entity, of any type, capable of observing its /environment/ and acting upon it. The concept of an agent is not strict, it is just a method of introspection or analysis of a system. An agent's methods of perceiving its environment are called /sensors/, while its methods of interacting with its environment are called /actuators/. Just like an agent itself, the environment of an agent could be anything. The environment is usually limited to the /thing/ that an agent perceives or acts upon.

As an example a person's environment is the Earth; their sensors include eyes and ears and their actuators include limbs and digits. A machine might have cameras, microphones and thermometers as sensors and a collection of motors as actuators, acting within the environment of a warehouse. A computer program has sensors and actuators in the form of common IO interfaces, operating on a computer file system as its environment.

The term /percept/ is the information an agent's sensors are currently perceiving, while an agent's /percept sequence/ is the history of all the information the agent has perceived. The behaviour of an agent is given by the /agent function/ which maps all possible percept sequences (an infinite list) to an action, an example of a [[../maths/set_theory.org::*Functions][mathematical function]]. The binary relation which constitutes the agent function is an external model of an agent's behaviour. The action taken by an agent at any point is determined by a concrete /agent program/, rather than a mathematical model. An agent program typically takes the current percept as an argument and returns an action.

** Rationality

In order to exhibit intelligence, an agent must attempt to make the correct decision. The performance of an agent is evaluated by a /performance measure/. A rational agent selects the action expected to maximise its performance measure. An /omniscient/ agent knows the exact outcome of its actions, there is no uncertainty in its behaviour. A rational agent will not perform perfectly, but in most cases it should perform well.

** TODO Agent Structure                                           :noexport:
:LOGBOOK:
- State "TODO"       from              [2023-02-19 Sun 22:48]
:END:
:TMP:
Simple reflex agents respond directly to percepts, whereas model-based reflex agents maintain internal state to track aspects of the world that are not evident in the current percept. Goal-based agents act to achieve their goals, and utility-based agents try to maximise their own expected “happiness”.
:END:

** Task Environment

The environment of an agent is the space in which it perceives and operates. The /task environment/ of an agent is the "problem" which it is designed to solve. The task environment is composed of the performance measure, the environment itself and the agent's sensors and actuators. The task environment and hence the required agent can be categorised in a few key ways:

- The environment of an agent may be /fully/ or /partially observable/, or even completely /unobservable/, to an agent's sensors in a single percept.
- An environment is /deterministic/ if the subsequent state of the environment is entirely determined by the current state and the action of the agent; this is not the case in a /stochastic/ or /nondeterministic/ environment.
- In an /episodic/ environment the selected action is determined by a single (the current) percept, not any previous information, and the selected action will not affect subsequent actions. If an agent's actions affect future decisions, the environment is sequential.
- A /static/ environment does not change between actions. A /dynamic/ environment changes constantly and the agent defaults to the action of nothing, except when it explicitly makes a decision. A /semidynamic/ environment does not change constantly, but the performance of an agent decreases with time.
- The usual meanings of /continuous/ and /discrete/ hold with respect to the state of the environment, time and the percepts and actions of the agent.
- A task environment may be completely or partially /known/ or /unknown/ to the agent. Any component of the task environment, including even the performance measure, could be unknown to the agent, differentiating this property from the environments deterministic/nondeterministic nature.
